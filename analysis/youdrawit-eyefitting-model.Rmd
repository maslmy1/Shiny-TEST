---
title: "Eye Fitting Straight Lines in the Modern Era"
subtitle: "Pilot Analysis"
author: "Emily Robinson"
date: "June 2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
library(knitr)
```

## SETUP

+ Load libraries
+ Functions for computing confidence intervals

```{r setup2}
library(tidyverse)
library(readr)
library(openssl)
library(mgcv)
library(lme4)
library(lmerTest)
library(emmeans)
library(pls)
`%!in%` = function(x,y) !(x %in% y)
source("gamm-predict-function.R")
```

## EYEFITTING DATA

+ Note that we have both the feedback data (includes x, y-aka yols, and ydrawn) and the simulated points (we need to use this to calculate the ypca values). 

```{r data}

# FEEDBACK DATA
feedback_smooth  <- read_csv("data/youdrawit-feedback-smooth.csv")
eyefitting_data <- feedback_smooth %>%
  filter(parm_id %in% c("S", "F", "V", "N")) %>%
  select(participantID, nick_name, study_starttime, age, gender, academic_study, recruitment, plotID, start_time, end_time, parm_id, x, y, ydrawn, yloess, residualdrawn, residualloess) %>%
  arrange(participantID, x)
factorCols = c('participantID', 'nick_name', 'age', 'gender', 'academic_study', 'recruitment', 'plotID', 'parm_id')
eyefitting_data[,factorCols] <- lapply(eyefitting_data[,factorCols], factor)
# summary(eyefitting_data)

# SIMULATED DATA
simulated_data <- read_csv("data/youdrawit-simulated-data.csv") %>%
  filter(study_starttime > 1620152231)  %>%
  mutate(study_starttime = round(study_starttime)) %>%
  mutate(participantID = md5(paste(nick_name, study_starttime)),
         plotID = md5(paste(nick_name, study_starttime, parm_id)))

factorCols = c('participantID', 'nick_name', 'plotID', 'parm_id', 'dataset')
simulated_data[,factorCols] <- lapply(simulated_data[,factorCols], factor)
# summary(simulated_data)

```

## FIRST PRINCIPAL COMPONENT

To calculate the first principal component fit:

1. Subset the simulated point data for a particular participant and parameter (S, F, V, N).
2. Fit a principal component over the x and y vectors from the point data (note these are the points show in the plot below). Use `prcomp`. Call this `pca.mod` 
3. Obtain the slope and intercept:
    + Using the pca.mod rotations we obatin the slope as: $\text{pca.slope} = \frac{\text{pca.mod rotation}[y,PC1]}{\text{pca.mod rotation}[x,PC1]}$
    + Using point-slope form we obtain the intercept as: $\text{pca.intercept} = \bar y_{\text{point_data}} - \text{pca.slope} \cdot \bar x_{\text{point_data}}$
4. Obtain ypca values by: $y_{pca} = \text{pca.slope} \cdot x_{\text{feedback data}} + \text{pca.intercept}$

### Trial

+ Grabbing one particular participant ID and parameter value, we test out the PCA code/calculation. The plot below shows the OLS fit, PCA fit, User drawn line, and simulated points.

```{r pca-trail}
# Trial Data
participantIDs <- levels(eyefitting_data$participantID)
trial.sim <- simulated_data %>%
  filter(participantID == participantIDs[18], parm_id == "F", dataset == "point_data")
trial.feedback <- eyefitting_data %>%
  filter(participantID == participantIDs[18], parm_id == "F")

# PCA
trial.pca <- prcomp(trial.sim[,c("x","y")])
trial.pca$rotation
pca.slope <- trial.pca$rotation[2,1]/trial.pca$rotation[1,1]
pca.intercept <- mean(trial.sim$y) - pca.slope*(mean(trial.sim$x))
trial.feedback$ypca <- pca.slope*trial.feedback$x + pca.intercept

write.csv(trial.feedback, file = "results/youdrawit-eyefitting-example-feedback.csv", row.names = F, na = "")
write.csv(trial.sim, file = "results/youdrawit-eyefitting-example-simulated.csv", row.names = F, na = "")

trial.feedback %>%
  ggplot(aes(x = x)) +
  geom_line(aes(y = y, color = "OLS", linetype = "OLS")) +
  geom_line(aes(y = ypca, color = "PCA", linetype = "PCA")) +
  geom_line(aes(y = ydrawn, color = "Drawn (loess)", linetype = "Drawn (loess)")) +
  geom_point(data = trial.sim, aes(y = y)) +
  facet_wrap(~parm_id) +
  theme_bw() +
  theme(aspect.ratio = 1,
        legend.position = "bottom") +
  scale_x_continuous(limits = c(0,20)) +
  scale_color_manual("", values = c("steelblue", "black", "black")) +
  scale_linetype_manual("", values = c("solid", "solid", "dashed"))
```

### Calculate all PCA
```{r pcaCalc}
# Fit PCA
pcaCalc <- function(data){
  point.data <- simulated_data %>% 
    mutate(participantID = as.character(participantID),
           parm_id = as.character(parm_id)) %>%
    filter(dataset == "point_data", participantID == as.character(data[1,"participantID"]), parm_id == as.character(data[1, 'parm_id']))
  
  pca.mod   <- prcomp(point.data[,c("x","y")])
  pca.slope <- pca.mod$rotation[2,1]/pca.mod$rotation[1,1]
  pca.intercept <- mean(point.data$y) - pca.slope*(mean(point.data$x))
  return(pca.slope*data$x + pca.intercept)
}

eyefitting_model_data <- eyefitting_data %>% 
  mutate(participantID = as.character(participantID),
         parm_id = as.character(parm_id)) %>%
  tidyr::nest(-plotID) %>%
  dplyr::mutate(ypca = purrr::map(data, pcaCalc)) %>%
  tidyr::unnest(cols = c(data, ypca)) %>%
  mutate(residualpca = ydrawn - ypca,
         residualpca.loess = yloess - ypca,
         participantID = factor(participantID),
         parm_id = factor(parm_id)) %>%
  rename(yols = y,
         residualols = residualdrawn,
         residualols.loess = residualloess) %>%
  dplyr::select(participantID, nick_name, study_starttime, age, gender, academic_study, recruitment, plotID, start_time, end_time, parm_id, x, yols, ypca, ydrawn, yloess, residualols, residualols.loess, residualpca, residualpca.loess)

# write.csv(eyefitting_model_data, "results/youdrawit-eyefitting-model-data.csv", row.names = F, na = "")

# head(eyefitting_model_data)
```

## RAW DATA PLOTS

### yloess (OLS)
```{r yloess-ols-plot}
eyefitting_model_data %>%
  ggplot(aes(x = x)) +
  geom_line(aes(y = yloess, group = plotID), alpha = 0.5, color = "steelblue") +
  geom_line(alpha = 0.2, aes(y = yols, group = participantID)) +
  # geom_line(alpha = 0.2, aes(y = ypca, group = participantID), linetype = "dashed") +
  facet_wrap(~ parm_id) +
  theme_bw() +
  theme(aspect.ratio = 1) +
  scale_x_continuous(limits = c(0, 20)) +
  ggtitle("OLS")
```

### yloess (PCA)
```{r yloess-pca-plot}
eyefitting_model_data %>%
  ggplot(aes(x = x)) +
  geom_line(aes(y = yloess, group = plotID), alpha = 0.5, color = "steelblue") +
  # geom_line(alpha = 0.2, aes(y = yols, group = participantID)) +
  geom_line(alpha = 0.2, aes(y = ypca, group = participantID)) +
  facet_wrap(~ parm_id) +
  theme_bw() +
  theme(aspect.ratio = 1) +
  scale_x_continuous(limits = c(0, 20)) +
  ggtitle("PCA")
```

### Loess Residuals
```{r residual-plot}
eyefitting_model_data %>%
  ggplot(aes(x = x)) +
  geom_line(aes(y = residualols.loess, group = plotID, color = "OLS"), alpha = 0.3) +
  geom_line(aes(y = residualpca.loess, group = plotID, color = "PCA"), alpha = 0.3) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  facet_wrap(~parm_id) +
  theme_bw() +
  theme(aspect.ratio = 1) +
  scale_x_continuous(limits = c(0, 20)) +
  scale_color_manual("Estimate", values = c("steelblue", "orange"))
```

## GAMM MODELS

**Treatments:**

+ parm_ID (S, F, V, N)
+ x (0, 20)

**Response:** raw residuals

+ residualols = ydrawn - yols, denoted $e_{ols}$
+ residualpca = ydrawn - ypca, denoted $e_{pca}$

**Experimental Design:**    

+ Each participant saw each of the 4 plots (new simulated data for each)
    
**ANOVA Table:**

```{r, anova-gammm, echo = F}
sv <- c("participantID", "parm_id", "x", "x:parm_id", "residual")
df <- c("(50 - 1) = 49", "(4 - 1) = 3", "1", "(4 - 1) = 3", "143 - by subtraction")
data.frame("SV" = sv, "DF" = df) %>% kable()
```

**OLS GAMM Model:**

$$y_{drawn} - y_{ols} = e_{ij,ols} = \left[\gamma_0 + \alpha_i\right] + \left[s_1(x_{ij}) + s_{2i}(x_{ij}) \right] + p_{j} + \epsilon_{ij}$$

+ $\gamma_0$ is the overall intercept
+ $\alpha_i$ is the effect of the parameter combination on the intercept (i.e. how much the intercept adjusts for each parameter combo)
+ $s_1$ is the overall spline equation for x
+ $s_{2i}$ is the adjustment to the spline equation for each parameter combination (think unequal slopes)
+ $p_{j} \sim N(0, \sigma^2_{participant})$ is the participant error due to participant variation
+ $\epsilon_{ij} \sim N(0, \sigma^2)$ is the residual error.

**PCA GAMM Model:**

$$y_{drawn} - y_{pca} = e_{ij,pca} = \left[\gamma_0 + \alpha_i\right] + \left[s_1(x_{ij}) + s_{2i}(x_{ij}) \right] + p_{j} + \epsilon_{ij}$$

+ $\gamma_0$ is the overall intercept
+ $\alpha_i$ is the effect of the parameter combination on the intercept (i.e. how much the intercept adjusts for each parameter combo)
+ $s_1$ is the overall spline equation for x
+ $s_{2i}$ is the adjustment to the spline equation for each parameter combination (think unequal slopes)
+ $p_{j} \sim N(0, \sigma^2_{participant})$ is the participant error due to participant variation
+ $\epsilon_{ij} \sim N(0, \sigma^2)$ is the residual error.

*Question: do we need a x by participant spline? think autocorrelation.* 

```{r gamm, fig.height = 9}
# Fit GAMM

# OLS
# tic()
eyefitting.ols.gamm <- bam(residualols ~ parm_id + s(x) + s(x, by = parm_id) + 
                             s(participantID, bs = "re") +
                             s(x,participantID, bs = "re"),
            method = "REML",
            data = eyefitting_model_data)
# toc()
# summary(eyefitting.ols.gamm)
# anova(eyefitting.ols.gamm)
plot(eyefitting.ols.gamm, pages = 1, all.terms=TRUE)

# pca
# tic()
eyefitting.pca.gamm <- bam(residualpca ~ -1 + parm_id + s(x) +
                             s(x, by = parm_id) +
                             s(participantID, bs = "re") +
                             s(x,participantID, bs = "re"),
                           method = "REML",
                           data = eyefitting_model_data)
# toc()
# summary(eyefitting.pca.gamm)
# anova(eyefitting.pca.gamm)
plot(eyefitting.pca.gamm, pages = 1,all.terms=TRUE)

# Obtain Predictions
eyefitting.grid.gamm <- expand_grid(parm_id = c("S", "V", "F", "N"),
                                    x = seq(0,20, 0.5),
                                    participantID = eyefitting_model_data$participantID[1])

# OLS
eyefitting.ols.preds <- predict_gamm(eyefitting.ols.gamm, newdata = eyefitting.grid.gamm, se = T, re_form = NA)
eyefitting.grid.gamm$ols.pred <- eyefitting.ols.preds$prediction
eyefitting.grid.gamm$ols.lower <- eyefitting.ols.preds$prediction - (1.96 * eyefitting.ols.preds$se)
eyefitting.grid.gamm$ols.upper <- eyefitting.ols.preds$prediction + (1.96 * eyefitting.ols.preds$se)

# pca
eyefitting.pca.preds <- predict_gamm(eyefitting.pca.gamm, newdata = eyefitting.grid.gamm, se = T, re_form = NA)
eyefitting.grid.gamm$pca.pred <- eyefitting.pca.preds$prediction
eyefitting.grid.gamm$pca.lower <- eyefitting.pca.preds$prediction - (1.96 * eyefitting.pca.preds$se)
eyefitting.grid.gamm$pca.upper <- eyefitting.pca.preds$prediction + (1.96 * eyefitting.pca.preds$se)

# write.csv(eyefitting.grid.gamm, "results/youdrawit-eyefitting-gammpred-data.csv", row.names = F, na = "")

# Plot Predictions
eyefitting.grid.gamm %>%
  filter((parm_id %in% c("F", "N", "S") | (x <= 16 & x >= 4))) %>%
  ggplot(aes(x = x)) +
  geom_line(data = eyefitting_model_data, aes(x = x, y = residualpca, group = plotID, color = "PCA"), alpha = 0.1) +
  geom_line(data = eyefitting_model_data, aes(x = x, y = residualols, group = plotID, color = "OLS"), alpha = 0.1) +
  geom_ribbon(aes(ymin = ols.lower, ymax = ols.upper, fill = "OLS"), color = NA, alpha = 0.5) +
  geom_line(aes(y = ols.pred, color = "OLS")) +
  geom_ribbon(aes(ymin = pca.lower, ymax = pca.upper, fill = "PCA"), color = NA, alpha = 0.5) +
  geom_line(aes(y = pca.pred, color = "PCA")) +
  geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.5) +
  facet_wrap(~parm_id) +
  theme_bw() +
  theme(aspect.ratio = 1) +
  scale_y_continuous("Residual") +
  scale_color_manual("Estimates", values = c("steelblue", "orange")) +
  scale_fill_manual("Estimates", values = c("steelblue", "orange")) +
  ggtitle("Eyefitting GAMM")

# Plot Predictions
eyefitting.grid.gamm %>%
  filter((parm_id %in% c("F", "N", "S") | (x <= 16 & x >= 4))) %>%
  ggplot(aes(x = x)) +
  # geom_line(data = eyefitting_model_data, aes(x = x, y = residualpca, group = plotID, color = "PCA"), alpha = 0.1) +
  # geom_line(data = eyefitting_model_data, aes(x = x, y = residualols, group = plotID, color = "OLS"), alpha = 0.1) +
  geom_ribbon(aes(ymin = ols.lower, ymax = ols.upper, fill = "OLS"), color = NA, alpha = 0.5) +
  geom_line(aes(y = ols.pred, color = "OLS")) +
  geom_ribbon(aes(ymin = pca.lower, ymax = pca.upper, fill = "PCA"), color = NA, alpha = 0.5) +
  geom_line(aes(y = pca.pred, color = "PCA")) +
  geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.5) +
  facet_wrap(~parm_id) +
  theme_bw() +
  theme(aspect.ratio = 1) +
  scale_y_continuous("Residual") +
  scale_color_manual("Estimates", values = c("steelblue", "orange")) +
  scale_fill_manual("Estimates", values = c("steelblue", "orange")) +
  ggtitle("Eyefitting GAMM")
```

## LMER MODELS

**Treatments:**

+ parm_ID (S, F, V, N)
+ x (0, 20)

**Response:** raw residuals

+ residualols = ydrawn - yols, denoted $e_{ols}$
+ residualpca = ydrawn - ypca, denoted $e_{pca}$

**Experimental Design:**    

+ Each participant saw each of the 4 plots (new simulated data for each)
    
**ANOVA Table:**

```{r, anova-lmer, echo = F}
sv <- c("participantID", "parm_id", "x", "x:parm_id", "residual")
df <- c("(50 - 1) = 49", "(4 - 1) = 3", "1", "(4 - 1) = 3", "143 - by subtraction")
data.frame("SV" = sv, "DF" = df) %>% kable()
```

**OLS LMER Model:**

$$y_{drawn} - y_{ols} = e_{ij,ols} = \left[\gamma_0 + \alpha_i\right] + \left[\gamma_{1} x_{ij} + \gamma_{2i} x_{ij}\right] + p_{j} + \epsilon_{ij}$$

+ $\gamma_0$ is the overall intercept
+ $\alpha_i$ is the effect of the parameter combination on the intercept (i.e. how much the intercept adjusts for each parameter combo)
+ $\gamma_1$ is the overall slope for x
+ $\gamma_{2i}$ is the effect of the parameter combination on the slope (i.e. think unequal slopes)
+ $p_{j} \sim N(0, \sigma^2_{participant})$ is the participant error due to participant variation
+ $\epsilon_{ij} \sim N(0, \sigma^2)$ is the residual error.

**PCA LMER Model:**

$$y_{drawn} - y_{pca} = e_{ij,pca} = \left[\gamma_0 + \alpha_i\right] + \left[\gamma_{1} x_{ij} + \gamma_{2i} x_{ij}\right] + p_{j} + \epsilon_{ij}$$

+ $\gamma_0$ is the overall intercept
+ $\alpha_i$ is the effect of the parameter combination on the intercept (i.e. how much the intercept adjusts for each parameter combo)
+ $\gamma_1$ is the overall slope for x
+ $\gamma_{2i}$ is the effect of the parameter combination on the slope (i.e. think unequal slopes)
+ $p_{j} \sim N(0, \sigma^2_{participant})$ is the participant error due to participant variation
+ $\epsilon_{ij} \sim N(0, \sigma^2)$ is the residual error.

```{r lmer}
# Fit LMER

# OLS
# tic()
eyefitting.ols.lmer <- lmer(residualols ~ -1 + parm_id + x:parm_id + (1|participantID),
                       data = eyefitting_model_data)
# toc()
# summary(eyefitting.ols.lmer)
# anova(eyefitting.ols.lmer)

# pca
# tic()
eyefitting.pca.lmer <- lmer(residualpca ~ -1 + parm_id + x:parm_id + (1|participantID),
                            data = eyefitting_model_data)
# toc()
# summary(eyefitting.pca.lmer)
# anova(eyefitting.pca.lmer)

# Obtain Predictions
eyefitting.ols.grid.lmer  <- ref_grid(eyefitting.ols.lmer, at = list(x = seq(1,20,0.5)))
eyefitting.ols.preds.lmer <- emmeans(eyefitting.ols.grid.lmer, ~ parm_id:x, cov.reduce = FALSE) %>% 
  as_tibble()

eyefitting.pca.grid.lmer  <- ref_grid(eyefitting.pca.lmer, at = list(x = seq(1,20,0.5)))
eyefitting.pca.preds.lmer <- emmeans(eyefitting.pca.grid.lmer, ~ parm_id:x, cov.reduce = FALSE) %>% 
  as_tibble()

eyefitting.preds.lmer <- eyefitting.ols.preds.lmer %>%
  full_join(eyefitting.pca.preds.lmer, by = c("x", "parm_id"), suffix = c(".ols", ".pca"))

# write.csv(eyefitting.preds.lmer, "results/youdrawit-eyefitting-lmerpred-data.csv", row.names = F, na = "")


# Plot Predictions
eyefitting.preds.lmer %>%
  filter((parm_id %in% c("F", "N", "S") | (x <= 16 & x >= 4))) %>%
  ggplot(aes(x = x)) +
  geom_line(data = eyefitting_model_data, aes(x = x, y = residualols, group = plotID, color = "OLS"), alpha = 0.1) +
  geom_line(data = eyefitting_model_data, aes(x = x, y = residualpca, group = plotID, color = "PCA"), alpha = 0.1) +
  geom_ribbon(aes(ymin = asymp.LCL.ols, ymax = asymp.UCL.ols, fill = "OLS"), color = NA, alpha = 0.5) +
  geom_line(aes(y = emmean.ols, color = "OLS")) +
  geom_ribbon(aes(ymin = asymp.LCL.pca, ymax = asymp.UCL.pca, fill = "PCA"), color = NA, alpha = 0.5) +
  geom_line(aes(y = emmean.pca, color = "PCA")) +
  geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.5) +
  facet_wrap(~parm_id) +
  theme_bw() +
  theme(aspect.ratio = 1) +
  scale_y_continuous("Residual") +
  scale_color_manual("Estimates", values = c("steelblue", "orange")) +
  scale_fill_manual("Estimates", values = c("steelblue", "orange")) +
  ggtitle("Eyefitting LMER")

# Plot Predictions
eyefitting.preds.lmer %>%
  filter((parm_id %in% c("F", "N", "S") | (x <= 16 & x >= 4))) %>%
  ggplot(aes(x = x)) +
  # geom_line(data = eyefitting_model_data, aes(x = x, y = residualols, group = plotID, color = "OLS"), alpha = 0.1) +
  # geom_line(data = eyefitting_model_data, aes(x = x, y = residualpca, group = plotID, color = "PCA"), alpha = 0.1) +
  geom_ribbon(aes(ymin = asymp.LCL.ols, ymax = asymp.UCL.ols, fill = "OLS"), color = NA, alpha = 0.5) +
  geom_line(aes(y = emmean.ols, color = "OLS")) +
  geom_ribbon(aes(ymin = asymp.LCL.pca, ymax = asymp.UCL.pca, fill = "PCA"), color = NA, alpha = 0.5) +
  geom_line(aes(y = emmean.pca, color = "PCA")) +
  geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.5) +
  facet_wrap(~parm_id) +
  theme_bw() +
  theme(aspect.ratio = 1) +
  scale_y_continuous("Residual") +
  scale_color_manual("Estimates", values = c("steelblue", "orange")) +
  scale_fill_manual("Estimates", values = c("steelblue", "orange")) +
  ggtitle("Eyefitting LMER")
```

## Compare Sum of Squares (OLS VS PCA)

**Treatments:** 

+ parm_id (S, V, N, F)
+ Fit (OLS, PCA)

**Response:**

+ Sum of Squares (Ordinary)
    + $SS_{OLS} = \sum_{x\in[0,20]}(e^2_{ij,OLS})=\sum_{x\in[0,20]}\left((y_{ij,drawn} - y_{ij,OLS})^2\right)$
    + $SS_{PCA} = \sum_{x\in[0,20]}(e^2_{ij,PCA})=\sum_{x\in[0,20]}\left((y_{ij,drawn} - y_{ij,PCA})^2\right)$

**ANOVA Table:**

```{r, anova-SS, echo = F}
sv <- c("participantID", "parm_id", "fit", "parm_id:fit", "participantID:parm_id:fit - aka residual")
df <- c("(50 - 1) = 49", "(4 - 1) = 3", "(2 - 1) = 1", "(4 - 1)(2 - 1) = 3", "143 - by subtraction")
data.frame("SV" = sv, "DF" = df) %>% kable()
```

**Model:**

$$\log\left(SS_{ijk}\right) = \alpha_i + \beta_j + \alpha\beta_{ij} + p_{j} + \epsilon_{ij}$$

+ $\alpha_i$ denotes the effect of the $i^{th}$ parameter (S, F, V, N)
+ $\beta_j$ denotes the effect of the $j^{th}$ fit (OLS, PCA)
+ $\alpha\beta_{ij}$ denotes the interaction between the parameter combination and fit
+ $p_{j} \sim N(0, \sigma^2_{participant})$ is the error due to participant variation
+ $\epsilon_{ij} \sim N(0, \sigma^2)$ is the residual error.

```{r ss-analysis}
ss_data <- eyefitting_model_data %>%
  group_by(participantID, nick_name, study_starttime, age, gender, academic_study, recruitment, plotID, parm_id, start_time, end_time) %>%
  summarise(olsSS = sum(residualols^2),
            pcaSS = sum(residualpca^2),
            olsSS.loess = sum(residualols.loess^2),
            pcaSS.loess = sum(residualpca.loess^2)) %>%
  ungroup() %>%
  pivot_longer(cols = c("olsSS", "pcaSS", "olsSS.loess", "pcaSS.loess"),
               names_to = "Fit",
               values_to = "SS")

ss.lmer <- lmer(log(SS) ~ parm_id*Fit + (1|participantID),
              data = ss_data %>% filter(Fit %in% c("olsSS", "pcaSS")))
anova(ss.lmer)
plot(ss.lmer)

ss.emmeans <- emmeans(ss.lmer, ~parm_id:Fit, type = "response") %>%
  as_tibble()
write.csv(ss.emmeans, "results/youdrawit-ssEmmeans-lmer.csv", row.names = F, na = "")
ss.slicediffs <- pairs(emmeans(ss.lmer, ~Fit | parm_id, type = "response"), infer = c(TRUE, TRUE)) %>% 
  as_tibble()
write.csv(ss.slicediffs, "results/youdrawit-ssSlicediffs-lmer.csv", row.names = F, na = "")

ss.emmeans %>%
  ggplot(aes(x = parm_id, y = response, group = Fit, fill = Fit)) +
  geom_bar(stat = "identity", position = position_dodge(0.9)) +
  geom_errorbar(aes(ymin = lower.CL, ymax = upper.CL, width = 0.5), position = position_dodge(0.9)) +
  theme_bw() +
  theme(aspect.ratio = 0.75) +
  scale_fill_manual(values = c("steelblue", "orange"), labels = c("OLS", "PCA")) +
  scale_y_continuous("Sum of Squares") +
  scale_x_discrete("Data Set")

ss.slicediffs %>%
  ggplot(aes(x = ratio, y = parm_id)) +
  geom_point() +
  geom_errorbar(aes(xmin = lower.CL, xmax = upper.CL), width = 0.5) +
  geom_vline(xintercept = 1, linetype = "dashed") +
  theme_bw() +
  theme(aspect.ratio = 0.5) +
  scale_x_continuous("Sum of Squares Odds Ratio \n (OLS vs PCA)", limits = c(0,2.5), breaks = seq(0,2.5,0.5)) +
  scale_y_discrete("Data Set")
```